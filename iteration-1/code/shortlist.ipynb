{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdf350fc78862bca",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571cc70f-8f3c-4a31-adf4-406d78f0d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# hits that were \"redocked\" (placed) for scores and interactions\n",
    "ref = pd.read_pickle('fragmenstein_hit_replacements_pairs.pkl.gz')\n",
    "pairs = pd.read_pickle('fragmenstein_placed_pairs.pkl.gz')\n",
    "trio = pd.read_pickle('fragmenstein_placed_trio.pkl.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9c378c-ff46-45fa-bfbc-7f0a22f46d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([pairs, trio], ignore_index=True)\n",
    "analogs = combo.loc[combo.outcome == 'acceptable'].copy();\n",
    "len(ref), len(pairs), len(trio), len(combo), len(analogs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292c212fb17f865e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c79b0-a484-4da2-8b2e-4cf0f2200bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import operator\n",
    "from rdkit import Chem\n",
    "\n",
    "hits: List[Chem.Mol] = ref.hit_mols.apply(operator.itemgetter(0)).to_list()\n",
    "\n",
    "ori_weights = {\"N_rotatable_bonds\": 1.5,\n",
    "             \"\\u2206\\u2206G\": 1,\n",
    "             \"interaction_uniqueness_metric\": -3,\n",
    "             \"N_unconstrained_atoms\": 0.2,\n",
    "             \"N_constrained_atoms\": -0.1,\n",
    "             \"N_interactions\": -2,\n",
    "             \"N_interactions_lost\": 2,\n",
    "             \"max_hit_Tanimoto\": -0.3,\n",
    "             \"N_PAINS\": 7,\n",
    "             \"strain_per_HA\": 0.3}\n",
    "\n",
    "\n",
    "energy_weights = {\"N_rotatable_bonds\": 1,\n",
    "                  \"\\u2206\\u2206G\": 1,\n",
    "                  \"strain_per_HA\": 0.3}\n",
    "\n",
    "from fragmenstein import Laboratory\n",
    "\n",
    "Laboratory.score(analogs, ref,\n",
    "                 suffix='',\n",
    "                 hits=hits,\n",
    "                 weights=energy_weights,)\n",
    "\n",
    "analogs['energy_penalty'] = analogs.ad_hoc_penalty\n",
    "\n",
    "Laboratory.score(analogs, ref,\n",
    "                 suffix='',\n",
    "                 hits=hits,\n",
    "                 weights=ori_weights,)\n",
    "\n",
    "analogs['full_penalty'] = analogs.ad_hoc_penalty\n",
    "\n",
    "analogs = analogs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897a53d476437c5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## XChem only\n",
    "\n",
    "Get rid of non-xchem only vcs: in the mergers the native ligand and stolen PDB hits may be present.\n",
    "We want XChem only mergers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023c00c0-923f-4d14-a6e7-01e3343e6e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_xchem(names):\n",
    "    return any([name.replace('A71EV2A-', '')[0] == 'x' for name in names])\n",
    "\n",
    "analogs['xchem_based'] = analogs.hit_names.apply(has_xchem)\n",
    "analogs = analogs.loc[analogs.xchem_based]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eff6d7e413d576",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8641f4080ebe852",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# from kmodes.kmodes import KModes\n",
    "# import pandera.typing as pdt\n",
    "\n",
    "# k = 25\n",
    "\n",
    "# intxn_cols = [c for c in analogs.columns if isinstance(c, tuple)]\n",
    "# data_for_clustering = analogs.loc[analogs.outcome == 'acceptable'][intxn_cols].fillna(0)\n",
    "# tallies = data_for_clustering.sum().to_dict()\n",
    "# # probability scaled\n",
    "# data_for_clustering = data_for_clustering.apply(lambda col: col / tallies[col.name],axis=0).fillna(0)\n",
    "\n",
    "# #km = KModes(n_clusters=k, init='Huang', n_init=5, verbose=1)\n",
    "# #labels = km.fit_predict(data_for_clustering)\n",
    "\n",
    "# from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "# centroid, variance = kmeans(data_for_clustering.values, k)\n",
    "# labels, _ = vq(data_for_clustering.values, centroid)\n",
    "# # list to series first for the correct indices:\n",
    "# data_for_clustering['cluster_label']: pdt.Series[int] = labels\n",
    "# analogs['cluster_label']: pdt.Series[float] = data_for_clustering.cluster_label\n",
    "# analogs['cluster_label']: pdt.Series[int] = analogs['cluster_label'].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d8ee4e-471d-44da-a2b6-eaf61a000a6c",
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import kmeans, vq\n",
    "from kmodes.kmodes import KModes\n",
    "import pandera.typing as pdt\n",
    "import enum\n",
    "\n",
    "class clustering_algo(enum.Enum):\n",
    "    KMEAN = 1\n",
    "    KMODE = 2\n",
    "    \n",
    "class scaling_used(enum.Enum):\n",
    "    NONE = 0\n",
    "    CRUDE = 1\n",
    "    PROB = 2\n",
    "    FF = 3\n",
    "\n",
    "\n",
    "# rubbish scaled\n",
    "def rubbish_scale(col):\n",
    "    \"\"\"\n",
    "    This is in effect inferior intermolecular LJ\n",
    "    A hydrophobic is worth half, a salt bridge 2x\n",
    "    \n",
    "    :param col: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if col.name[0] == 'hydroph_interaction':\n",
    "        w = 0.5\n",
    "    if col.name[0] in 'halogenbond':\n",
    "        w = 1.5\n",
    "    elif col.name[0] == 'saltbridge':\n",
    "        w = 2.0\n",
    "    else:\n",
    "        w = 1.0\n",
    "    return col * w\n",
    "\n",
    "def force_score():\n",
    "    \"\"\"\n",
    "    a potential between the relative atoms that is \n",
    "    the Coulombic LJ with cosine weight for angle as seen in the Dreiding H-bond term,\n",
    "    https://docs.lammps.org/pair_hbond_dreiding.html#description\n",
    "    \"\"\"\n",
    "    # determine which is the two atoms: maths mod of neighbourhood extraction?\n",
    "    # extract the partial charge and atom type that Rosetta used\n",
    "    raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec888888976ee29",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# number of clusters sought\n",
    "k = 10\n",
    "scaling_mode = scaling_used.PROB\n",
    "\n",
    "intxn_cols = [c for c in analogs.columns if isinstance(c, tuple)]\n",
    "data_for_clustering = analogs.loc[analogs.outcome == 'acceptable'][intxn_cols].fillna(0).copy()\n",
    "tallies = data_for_clustering.sum().to_dict()\n",
    "\n",
    "if scaling_mode == scaling_used.PROB:\n",
    "    # probability scaled\n",
    "    data_for_clustering = data_for_clustering.apply(lambda col: col / tallies[col.name],axis=0).fillna(0)\n",
    "    algo = clustering_algo.KMEAN\n",
    "elif scaling_mode == scaling_used.CRUDE:\n",
    "    # A hydrophobic is worth half, a salt bridge 2x\n",
    "    data_for_clustering = data_for_clustering.apply(rubbish_scale, axis=0).fillna(0)\n",
    "    algo = clustering_algo.KMEAN\n",
    "elif scaling_mode == scaling_used.FF:\n",
    "    raise NotImplemented\n",
    "elif scaling_mode == scaling_used.NONE:\n",
    "    # no scaling so Kmode\n",
    "    algo = clustering_algo.KMODE\n",
    "else:\n",
    "    raise ValueError\n",
    "    \n",
    "if algo == clustering_algo.KMEAN:\n",
    "    centroid, variance = kmeans(data_for_clustering.values, k)\n",
    "    labels, _ = vq(data_for_clustering.values, centroid)\n",
    "elif algo == clustering_algo.KMODE:\n",
    "    km = KModes(n_clusters=k, init='Huang', n_init=5, verbose=1)\n",
    "    labels = km.fit_predict(data_for_clustering)\n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "# list to series first for the correct indices:\n",
    "data_for_clustering['cluster_label']: pdt.Series[int] = labels\n",
    "analogs['cluster_label']: pdt.Series[float] = data_for_clustering.cluster_label\n",
    "analogs['cluster_label']: pdt.Series[int] = analogs['cluster_label'].fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ef7a1-39e0-4c46-9119-6cddb163bab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from Bio.SeqUtils import seq1\n",
    "rank = defaultdict(int)\n",
    "\n",
    "def r(c):\n",
    "    rank[c] += 1\n",
    "    return rank[c]\n",
    "\n",
    "# 'cluster' is Similarity cluster\n",
    "analogs = analogs.sort_values('full_penalty').drop_duplicates('cluster').reset_index(drop=True)\n",
    "analogs['cluster_rank'] = analogs['cluster_label'].apply(r)\n",
    "analogs = analogs.sort_values(['cluster_rank', 'full_penalty']).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be581b52e755a36",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Make uploadable SDF for Fragalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37ac1d-2ea8-4860-87e2-c94a96904d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gist_import import GistImporter\n",
    "\n",
    "# fu for fragalysis upload\n",
    "fmodule = GistImporter.from_github('https://raw.githubusercontent.com/matteoferla/Fragment-hit-follow-up-chemistry/main/followup/prep_fragalysis.py')\n",
    "prep = fmodule['prep']\n",
    "generate_header = fmodule['generate_header']\n",
    "floatify_columns = fmodule['floatify_columns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad2f26c8ac344eb",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def narrate(row: pd.Series):\n",
    "    grouped = defaultdict(list)\n",
    "    for name, value in row.items():\n",
    "        if not isinstance(name, tuple) or value == 0.:\n",
    "            continue\n",
    "        itxn_type, resn, resi = name\n",
    "        grouped[itxn_type].append(seq1(resn, undef_code=\"X\")+str(resi))\n",
    "    narrative = f'cluster #{row.cluster_label} (rank {row.cluster_rank}); '\n",
    "    for itxn_type in sorted(grouped):\n",
    "        narrative += f'{itxn_type}:{\"+\".join(grouped[itxn_type])}; '\n",
    "    return narrative\n",
    "\n",
    "analogs['rationale'] = 'info ' + analogs.apply(narrate, axis=1)\n",
    "assert analogs['rationale'].apply(len).max() < 255, 'Fix length!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf87d8-237c-4e4d-8382-92fc2b172298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def catalogize(name):\n",
    "    if name[0] == 'Z':\n",
    "        return name.split('-')[0]\n",
    "    if name[0] == 'P':\n",
    "        return 'PV-'+name.split('-')[1]\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "analogs['catalog_id'] = analogs.name.apply(catalogize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13982c9f-133f-47cb-8493-4479c2cf35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_key_types = {'rationale': str, \n",
    "               'cluster_rank': int,\n",
    "               'N_interactions': int, \n",
    "               'N_interactions_lost': int,\n",
    "               '∆∆G': float, \n",
    "                    'comRMSD': float,\n",
    "                    'N_rotatable_bonds': int, \n",
    "                     'N_unconstrained_atoms': int,\n",
    "                    'N_constrained_atoms': int\n",
    "                   }\n",
    "\n",
    "for k, ktype in wanted_key_types.items():\n",
    "    analogs[k] = analogs[k].astype(ktype)\n",
    "\n",
    "wanted_keys = list(wanted_key_types)\n",
    "\n",
    "def clean_names(names):\n",
    "    deprefixed = [name.replace('A71EV2A-', '').split('S')[0] for name in names]\n",
    "    return ','.join([name for name in deprefixed if name[0] == 'x'])\n",
    "\n",
    "analogs['ref_mols'] = analogs.hit_names.apply(clean_names)\n",
    "\n",
    "header: Chem.Mol = generate_header(method='A71-Fragmenstein',\n",
    "                         ref_url='https://www.example.com',\n",
    "                         submitter_name='Matteo Ferla',\n",
    "                         submitter_email='matteo.ferla@stats.ox.ac.uk',\n",
    "                         submitter_institution='University of Oxford',\n",
    "                         extras=dict(zip(wanted_keys, wanted_keys))\n",
    "                                  )\n",
    "                                   \n",
    "prep(analogs.head(200), \n",
    "     header, mol_col='minimized_mol', \n",
    "     name_col='catalog_id',\n",
    "     outfile=f'A71_fragmenstein_clustered4.sdf',\n",
    "     ref_pdb_name='x0554_0A',\n",
    "     extras=wanted_keys\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c11636686222abd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae95880-fe91-4b13-bbf9-f759ac676d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "Draw.MolsToGridImage(analogs.head(20).smiles.apply(Chem.MolFromSmiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3592609beb9f62",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Junkyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc01ef0-08b7-4a43-81f8-6c2d2f3b85bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import numpy.typing as npt\n",
    "\n",
    "# cluster_itxns = []\n",
    "# for i in range(25):\n",
    "#     wanted = list( *np.where(centroid[i] > 0) )\n",
    "#     cluster_itxns.append( sorted([itxn for x, itxn in enumerate(intxn_cols) if x in wanted], key=operator.itemgetter(0)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce59214-a62a-4015-8665-2ec5acb59163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from Bio.SeqUtils import seq1\n",
    "\n",
    "# def narrate(row: npt.ArrayLike[float], labels: List[Tuple[str, str, int]]):\n",
    "#     wanted = list( *np.where(centroid_row > 0) )\n",
    "#     itxns = [itxn for x, itxn in enumerate(labels) if x in wanted]\n",
    "#     grouped = defaultdict(list)\n",
    "#     for itxn_type, resn, resi in itxns:\n",
    "#         grouped[itxn_type].append(seq1(resn, undef_code=\"X\")+str(resi))\n",
    "    \n",
    "#     return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a13a0-0f05-4b19-8d59-c2edba97acea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaabc74-cdf1-4daf-94a3-aa656bfa84f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04b064e-3d35-419d-a45a-8a994d9b67a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "fps = [AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=2048) for mol in analogs.minimized_mol]\n",
    "fp_array: npt.NDArray[bool] = np.array([list(fp) for fp in fps])\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(fp_array)\n",
    "\n",
    "# Create a DataFrame for the t-SNE results\n",
    "tsne_df = pd.DataFrame(tsne_results, columns=['TSNE-1', 'TSNE-2'])\n",
    "\n",
    "# Plot the t-SNE results using Plotly Express\n",
    "fig = px.scatter(tsne_df, x='TSNE-1', y='TSNE-2', title='t-SNE Visualization of Compounds')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:compchem]",
   "language": "python",
   "name": "conda-env-compchem-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
